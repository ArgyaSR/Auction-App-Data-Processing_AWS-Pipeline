# üî® Auction Data Pipeline

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Apache Kafka](https://img.shields.io/badge/Kafka-3.6-orange.svg)](https://kafka.apache.org/)
[![Apache Spark](https://img.shields.io/badge/Spark-3.5-yellow.svg)](https://spark.apache.org/)
[![AWS](https://img.shields.io/badge/AWS-Free%20Tier-orange.svg)](https://aws.amazon.com/free/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

A production-grade, end-to-end data pipeline for processing real-time auction bids and batch analytics. Built with modern data engineering practices using Apache Kafka, Spark Structured Streaming, PostgreSQL, Apache Airflow, and AWS services.

## üìã Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Tech Stack](#tech-stack)
- [Quick Start](#quick-start)
- [Project Structure](#project-structure)
- [Data Flow](#data-flow)
- [Configuration](#configuration)
- [Deployment](#deployment)
- [Testing](#testing)
- [Monitoring](#monitoring)
- [Contributing](#contributing)

## üéØ Overview

This pipeline solves the data engineering challenges of a high-traffic auction platform:

- **Problem**: An auction web app experiencing growth pains‚Äîslow page loads, application downtime, and inability to process thousands of concurrent bids
- **Solution**: Event-driven architecture with Kafka for ingestion decoupling, Spark for scalable processing, and a medallion data architecture for clean analytics

### Key Capabilities

| Capability | Metric |
|------------|--------|
| Bid Processing Throughput | 10,000+ events/second |
| End-to-End Latency | < 500ms (streaming path) |
| Data Freshness | Real-time for active auctions |
| Historical Analytics | Daily batch aggregations |

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                              DATA SOURCES                                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   Auction API   ‚îÇ   IoT/POS       ‚îÇ   Batch Files   ‚îÇ   Historical Data     ‚îÇ
‚îÇ   (Real-time)   ‚îÇ   Devices       ‚îÇ   (CSV/JSON)    ‚îÇ   (S3)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                 ‚îÇ                 ‚îÇ                   ‚îÇ
         ‚ñº                 ‚ñº                 ‚ñº                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                           INGESTION LAYER                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ                      Apache Kafka (KRaft Mode)                       ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  Topics: auction.bids | auction.items | auction.users | auction.txn ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚ñº                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      STREAM PROCESSING        ‚îÇ ‚îÇ           BATCH PROCESSING                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Spark Structured       ‚îÇ  ‚îÇ ‚îÇ  ‚îÇ  Apache Spark (Batch Jobs)          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Streaming              ‚îÇ  ‚îÇ ‚îÇ  ‚îÇ  - Daily aggregations               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Real-time bid        ‚îÇ  ‚îÇ ‚îÇ  ‚îÇ  - Historical analytics             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    validation           ‚îÇ  ‚îÇ ‚îÇ  ‚îÇ  - ML feature engineering           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Price updates        ‚îÇ  ‚îÇ ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  ‚îÇ  - Fraud detection      ‚îÇ  ‚îÇ ‚îÇ                                           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ ‚îÇ  Orchestrated by Apache Airflow           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ                                       ‚îÇ
                ‚ñº                                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                            STORAGE LAYER                                     ‚îÇ
‚îÇ                         (Medallion Architecture)                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îÇ
‚îÇ  ‚îÇ   BRONZE     ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   SILVER     ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    GOLD      ‚îÇ                   ‚îÇ
‚îÇ  ‚îÇ   (S3)       ‚îÇ    ‚îÇ (PostgreSQL) ‚îÇ    ‚îÇ  (DuckDB/    ‚îÇ                   ‚îÇ
‚îÇ  ‚îÇ  Raw Events  ‚îÇ    ‚îÇ   Cleaned    ‚îÇ    ‚îÇ   Analytics) ‚îÇ                   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          VISUALIZATION LAYER                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ       Metabase          ‚îÇ    ‚îÇ      Application API                ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ   (BI Dashboards)       ‚îÇ    ‚îÇ   (Real-time auction data)          ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üõ†Ô∏è Tech Stack

| Layer | Technology | Purpose |
|-------|------------|---------|
| **Ingestion** | Apache Kafka (KRaft) | Event streaming, decoupling |
| **Stream Processing** | Spark Structured Streaming | Real-time transformations |
| **Batch Processing** | Apache Spark | Daily aggregations, ETL |
| **Orchestration** | Apache Airflow | Workflow scheduling |
| **Operational DB** | PostgreSQL | Application data, Silver layer |
| **Data Lake** | AWS S3 / LocalStack | Bronze layer, raw storage |
| **Analytics DB** | DuckDB | OLAP queries, Gold layer |
| **Visualization** | Metabase | Dashboards, reporting |
| **Infrastructure** | Terraform | Infrastructure as Code |
| **Containerization** | Docker Compose | Local development |

## üöÄ Quick Start

### Prerequisites

- Docker Desktop 4.0+ with WSL2 backend (Windows)
- Python 3.11+
- Make (optional, for convenience commands)
- AWS CLI (for cloud deployment)

### One-Command Setup

```bash
# Clone the repository
git clone https://github.com/yourusername/auction-data-pipeline.git
cd auction-data-pipeline

# Copy environment template
cp .env.example .env

# Start all services
make up

# Or without Make:
docker compose up -d
```

### Access Points

| Service | URL | Credentials |
|---------|-----|-------------|
| Kafka UI | http://localhost:8080 | - |
| Airflow | http://localhost:8081 | airflow / airflow |
| Metabase | http://localhost:3000 | Setup on first visit |
| PostgreSQL | localhost:5432 | auction / auction123 |

### Generate Sample Data

```bash
# Start the data generator (produces to Kafka)
make generate-data

# Or run directly:
python -m src.data_generator.kafka_producer --events 10000 --rate 100
```

### Run the Pipeline

```bash
# Start Spark streaming job
make run-streaming

# Trigger batch processing via Airflow UI or:
make run-batch
```

## üìÅ Project Structure

```
auction-data-pipeline/
‚îú‚îÄ‚îÄ README.md                       # This file
‚îú‚îÄ‚îÄ docker-compose.yml              # All services orchestration
‚îú‚îÄ‚îÄ Makefile                        # Convenience commands
‚îú‚îÄ‚îÄ .env.example                    # Environment template
‚îú‚îÄ‚îÄ requirements.txt                # Python dependencies
‚îú‚îÄ‚îÄ pyproject.toml                  # Project metadata
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data_generator/             # Synthetic data generation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generator.py            # Core data generation logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas.py              # Data models (Pydantic)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kafka_producer.py       # Stream events to Kafka
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ batch_generator.py      # Generate batch files
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/                  # Data ingestion layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kafka_consumer.py       # Base Kafka consumer
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ s3_ingestion.py         # S3 batch ingestion
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ transformation/             # Processing layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ spark_streaming.py      # Spark Structured Streaming
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ batch_processing.py     # Spark batch jobs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transformations.py      # Business logic transforms
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ serving/                    # Data serving layer
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ postgres_loader.py      # Load to PostgreSQL
‚îÇ       ‚îî‚îÄ‚îÄ duckdb_analytics.py     # DuckDB analytics queries
‚îÇ
‚îú‚îÄ‚îÄ dags/                           # Airflow DAGs
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ auction_streaming_dag.py    # Streaming job management
‚îÇ   ‚îî‚îÄ‚îÄ batch_processing_dag.py     # Daily batch ETL
‚îÇ
‚îú‚îÄ‚îÄ sql/                            # Database schemas
‚îÇ   ‚îú‚îÄ‚îÄ init.sql                    # Initial setup
‚îÇ   ‚îú‚îÄ‚îÄ bronze_schema.sql           # Raw data schema
‚îÇ   ‚îú‚îÄ‚îÄ silver_schema.sql           # Cleaned data schema
‚îÇ   ‚îî‚îÄ‚îÄ gold_schema.sql             # Analytics schema
‚îÇ
‚îú‚îÄ‚îÄ terraform/                      # Infrastructure as Code
‚îÇ   ‚îú‚îÄ‚îÄ main.tf                     # Main configuration
‚îÇ   ‚îú‚îÄ‚îÄ variables.tf                # Input variables
‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf                  # Output values
‚îÇ   ‚îú‚îÄ‚îÄ s3.tf                       # S3 bucket config
‚îÇ   ‚îú‚îÄ‚îÄ rds.tf                      # RDS PostgreSQL config
‚îÇ   ‚îî‚îÄ‚îÄ iam.tf                      # IAM roles and policies
‚îÇ
‚îú‚îÄ‚îÄ tests/                          # Test suite
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py                 # Pytest fixtures
‚îÇ   ‚îú‚îÄ‚îÄ test_generator.py           # Data generator tests
‚îÇ   ‚îú‚îÄ‚îÄ test_transformations.py     # Transform logic tests
‚îÇ   ‚îî‚îÄ‚îÄ integration/                # Integration tests
‚îÇ       ‚îî‚îÄ‚îÄ test_pipeline.py
‚îÇ
‚îú‚îÄ‚îÄ config/                         # Configuration files
‚îÇ   ‚îú‚îÄ‚îÄ spark-defaults.conf         # Spark configuration
‚îÇ   ‚îî‚îÄ‚îÄ log4j2.properties           # Logging config
‚îÇ
‚îú‚îÄ‚îÄ docs/                           # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE.md             # Detailed architecture
‚îÇ   ‚îú‚îÄ‚îÄ SETUP.md                    # Setup instructions
‚îÇ   ‚îî‚îÄ‚îÄ adr/                        # Architecture Decision Records
‚îÇ       ‚îú‚îÄ‚îÄ 001-kafka-over-kinesis.md
‚îÇ       ‚îî‚îÄ‚îÄ 002-spark-over-flink.md
‚îÇ
‚îî‚îÄ‚îÄ .github/
    ‚îî‚îÄ‚îÄ workflows/
        ‚îî‚îÄ‚îÄ ci.yml                  # GitHub Actions CI/CD
```

## üåä Data Flow

### Real-Time Path (Streaming)

1. **Bid Placed** ‚Üí Auction API publishes event to Kafka `auction.bids` topic
2. **Spark Streaming** consumes events, validates bids, updates current prices
3. **PostgreSQL** receives validated bid records (Silver layer)
4. **Application** queries PostgreSQL for current auction state

### Batch Path (Analytics)

1. **Airflow** triggers daily at 2 AM UTC
2. **Spark Batch** reads from Bronze (S3), applies transformations
3. **Gold Layer** aggregations written to DuckDB/PostgreSQL
4. **Metabase** dashboards refresh with new data

### Data Schema Overview

```
Users (1) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ< Bids (‚àû)
  ‚îÇ                    ‚îÇ
  ‚îÇ                    ‚îÇ
  ‚îî‚îÄ‚îÄ< Items (‚àû) >‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ
    Transactions (‚àû)
```

## ‚öôÔ∏è Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `KAFKA_BOOTSTRAP_SERVERS` | Kafka broker addresses | `localhost:9092` |
| `POSTGRES_HOST` | PostgreSQL host | `localhost` |
| `POSTGRES_DB` | Database name | `auction` |
| `AWS_REGION` | AWS region for S3 | `us-east-1` |
| `S3_BUCKET` | Data lake bucket name | `auction-data-lake` |

### Spark Tuning

Edit `config/spark-defaults.conf` for production workloads:

```properties
spark.executor.memory=2g
spark.executor.cores=2
spark.sql.shuffle.partitions=200
```

## ‚òÅÔ∏è Deployment

### AWS Free Tier Deployment

```bash
cd terraform

# Initialize Terraform
terraform init

# Preview changes
terraform plan

# Deploy infrastructure
terraform apply

# Get outputs (RDS endpoint, S3 bucket name)
terraform output
```

### Cost Estimation (Free Tier)

| Service | Monthly Cost |
|---------|--------------|
| S3 (5GB) | $0 |
| RDS db.t3.micro | $0 |
| Lambda (if used) | $0 |
| **Total** | **$0-5** |

## üß™ Testing

```bash
# Run all tests
make test

# Run with coverage
make test-coverage

# Run specific test file
pytest tests/test_generator.py -v

# Run integration tests (requires Docker)
make test-integration
```

## üìä Monitoring

### Kafka Metrics (via Kafka UI)

- Consumer lag per partition
- Message throughput
- Topic sizes

### Spark Metrics

Access Spark UI at `http://localhost:4040` during job execution:
- Stage progress
- Memory usage
- Shuffle statistics

### Custom Dashboards (Metabase)

Pre-configured dashboards include:
- Real-time bidding activity
- Daily revenue trends
- User engagement metrics
- Auction success rates

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- [Apache Kafka](https://kafka.apache.org/) for the streaming platform
- [Apache Spark](https://spark.apache.org/) for data processing
- [Confluent](https://developer.confluent.io/) for Kafka documentation
- [DuckDB](https://duckdb.org/) for embedded analytics

---

**Built with ‚ù§Ô∏è for learning modern data engineering**
